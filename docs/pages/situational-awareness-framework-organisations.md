---
layout: default
title: Situational-awareness-framework - selfdrivenAI
permalink: /situational-awareness-framework/organisations/
---

# Situational Awareness Framework for Organisations

<img src="/assets/img/selfdriven-ai-before-after-situational-awareness-level.png" style="border-radius: 12px; width:100%; max-width: 800px;">

*Levels represent the situation and mindset.*

## 1. Legacy — "Human in Control"
"We make all the decisions. The tools just do what we say."

### Mindset Characteristics
- Technology is a support function.
- Decision-making is manual, hierarchical, and slow.
- AI is approached with suspicion or avoidance.
- Data is siloed and owned by departments.
- Innovation = incremental improvement, not transformation.

### Future Relevance
- Risk: Loss of competitiveness; human bottlenecks; slower adaptation.
- Relevance Horizon: 2–3 years before operations feel outdated.
- Impact: Efficiency-focused organisations fall behind insight-driven ones.

### Evolution Focus
- Build AI literacy across leadership and staff.
- Start data integration and cross-department collaboration.
- Pilot decision-support AI to augment (not replace) human expertise.

---

## 2. Transitional — "Human + Machine Collaboration"
> "We decide with the machine, not just through it."

### Mindset Characteristics
- AI is treated as a partner in decision-making.
- Staff are trained to interpret and challenge AI outputs.
- Data is a shared strategic asset.
- Decisions move closer to where data lives.
- Governance emphasises explainability and bias mitigation.

### Future Relevance
- Advantage: Faster, insight-rich decision cycles.
- Risk: Over-trusting unexamined algorithms ("AI says so").
- Relevance Horizon: 3–5 years with adaptive governance.

### Evolution Focus
- Establish AI ethics and decision-oversight frameworks.
- Track decision provenance (why/how choices are made).
- Form cross-functional teams to co-design human–machine workflows.

---

## 3. Emerging — "Machine in Control / Human in Context"
"We define direction, not decisions."

### Mindset Characteristics
- Machines execute adaptive strategies within human-defined boundaries.
- Humans focus on values, ethics, and direction-setting.
- Continuous AI governance monitors drift and outcomes.
- The organisation behaves like an ecosystem, not a strict hierarchy.
- Culture prizes stewardship, creativity, and alignment.

### Future Relevance
- Advantage: Scalable intelligence beyond human limits.
- Risk: Ethical drift, loss of agency, misalignment with human or social goals.
- Relevance Horizon: Long-term, dependent on robust trust frameworks.

### Evolution Focus
- Define and encode an AI Constitution or Values Charter.
- Use recursive oversight AI ("AI watching AI") for alignment.
- Redefine leadership around meaning, foresight, and human purpose.

---

## Summary

| Mindset Level | Description | Strategic Risk | Relevance Horizon | Evolution Focus |
|:---------------|:---------- |:---------------|:------------------|:----------------|
| 1. Human-in-Control | Humans make all decisions; tools follow | Obsolescence | 2–3 years | AI literacy, data integration        |
| 2. Human + Machine  | Shared decisions; humans interpret AI | Bias / drift | 3–5 years | Explainability, oversight, provenance|
| 3. Machine-in-Control | Machines act autonomously within human ethics | Alignment loss | Long-term | Trust frameworks, ethical governance |